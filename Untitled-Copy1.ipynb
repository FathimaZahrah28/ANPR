{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38485126-6185-47ce-9b1b-034ef6f2a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import imutils\n",
    "import easyocr\n",
    "import webbrowser\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "353a201a-be83-4e5d-8243-f03ccc58d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(text1, text2, csv_filename):\n",
    "    with open(csv_filename, mode='a', newline='') as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow([text1], [text2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f482c4a9-581c-473c-979c-bb566058d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_plat(images):\n",
    "    import imutils\n",
    "    img = cv2.imread(images)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #Grayscale and Blur\n",
    "    #Apply filter and find edges for localization\n",
    "    bfilter = cv2.bilateralFilter(gray, 11, 17, 17) #Noise reduction\n",
    "    edged = cv2.Canny(bfilter, 30, 200) #Edge detection\n",
    "    # Find Contours and Apply Mask\n",
    "    keypoints = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(keypoints)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "    \n",
    "    location = None\n",
    "    for contour in contours:\n",
    "        approx = cv2.approxPolyDP(contour, 10, True)\n",
    "        if len(approx) == 4:\n",
    "            location = approx\n",
    "            break\n",
    "            \n",
    "    mask = np.zeros(gray.shape, np.uint8)\n",
    "    new_image = cv2.drawContours(mask, [location], 0,255, -1)\n",
    "    new_image = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    (x,y) = np.where(mask==255)\n",
    "    (x1, y1) = (np.min(x), np.min(y))\n",
    "    (x2, y2) = (np.max(x), np.max(y))\n",
    "    cropped_image = gray[x1:x2+1, y1:y2+1]\n",
    "    \n",
    "    #use easy ocr to read text\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    result = reader.readtext(cropped_image)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5fd1a00-66b6-449e-a1a1-5e7d01016264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def cek(filename):\n",
    "    with open(csv_filename, mode='r', newline='') as f:\n",
    "        csv_reader = csv.reader(f)\n",
    "        rows = list(csv_reader)\n",
    "\n",
    "        if len(rows) >= 2:  # Memastikan minimal ada dua baris untuk dibandingkan\n",
    "            text1 = rows[0][count]  # Mengambil nilai dari baris pertama\n",
    "            text2 = rows[1][count] # Mengambil nilai dari baris kedua\n",
    "\n",
    "            # Membandingkan nilai dari kedua baris\n",
    "            if text1 == text2:\n",
    "                return print(\"silahkan lewat\")\n",
    "            else:\n",
    "                return print(\" tidak cocok.\")\n",
    "        else:\n",
    "            return print(\"Tidak cukup baris untuk dibandingkan.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87e2865f-59f3-4b9a-a2d6-d835c9f06dce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1204/2167319067.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m \u001b[0mtext_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_plat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[0msave_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'plat_nom.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "harcascade = \"model/haarcascade_russian_plate_number.xml\"\n",
    "detector = cv2.QRCodeDetector()\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(3, 640) # width\n",
    "cap.set(4, 480) #height\n",
    "\n",
    "min_area = 500\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    data, _, _ = detector.detectAndDecode(img)\n",
    "\n",
    "    plate_cascade = cv2.CascadeClassifier(harcascade)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    plates = plate_cascade.detectMultiScale(img_gray, 1.1, 4)\n",
    "    \n",
    "    cv2.imshow(\"Result\", img)\n",
    "    for (x,y,w,h) in plates:\n",
    "        area = w * h\n",
    "        \n",
    "\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "            cv2.putText(img, \"Number Plate\", (x,y-5), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (255, 0, 255), 2)\n",
    "\n",
    "            img_roi = img[y: y+h, x:x+w]\n",
    "            cv2.imshow(\"ROI\", img_roi)\n",
    "            cv2.putText(img, \"Number Plate Detected\", (x, y - 5), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (255, 0, 255),\n",
    "                        2)\n",
    "            cv2.imwrite(\"detected_plates/scaned_img_\" + str(count) + \".jpg\", img_roi)\n",
    "            break\n",
    "        images = \"detected_plates/scaned_img_\" + str(count) + \".jpg\"\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    if data:\n",
    "        if data.startswith('http') or data.startswith('https'):\n",
    "            # Jika QR code berisi URL, buka di web browser\n",
    "            webbrowser.open(data)\n",
    "            break\n",
    "        else:\n",
    "            # Jika QR code berisi teks, tampilkan teksnya\n",
    "            text_2 = data\n",
    "            break\n",
    "            \n",
    "    cv2.imshow(\"Result\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to quit the loop\n",
    "        break\n",
    "\n",
    "# Release the camera and close all windows when 'q' is pressed\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "text_1 = read_plat(images)\n",
    "save_results(text_1, text_2, 'plat_nom.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c59537ff-a8b3-4b16-8197-ca5a168328bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_plat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4176/2729170116.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mread_plat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TEST/TEST1.jpeg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'read_plat' is not defined"
     ]
    }
   ],
   "source": [
    "read_plat('TEST/TEST1.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "325c5915-32ae-45b8-be3d-50f56f4eee52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('TEST/TEST1.jpeg')\n",
    "#Converting the image to gray-scale\n",
    "image_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#Blurring the image with a 11x11 mask\n",
    "blured_image = cv2.GaussianBlur(image_gray,(11,11),0)\n",
    "#Finding the edges of the non blurred image\n",
    "edge_image_blur = cv2.Canny(blured_image,30,100)\n",
    "#Finding the edges of blurred image\n",
    "edge_image_normal = cv2.Canny(image_gray,30,100)\n",
    "\n",
    "key_points=cv2.findContours(edge_image_blur,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "#defining contours from keypoints\n",
    "contours = imutils.grab_contours(key_points)\n",
    "#drawing contours\n",
    "cv2.drawContours(img, contours, -1, (0,255,0), 3)\n",
    "\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)[:20]\n",
    "plate_location = None\n",
    "for cnt in contours:\n",
    " sqaure_approx = cv2.approxPolyDP(cnt, 10, True)\n",
    " if len(sqaure_approx) == 4:\n",
    "   plate_location = sqaure_approx\n",
    "x1, x2 = min(plate_location[:,0][:,1]), max(plate_location[:,0][:,1])\n",
    "y1, y2 = min(plate_location[:,0][:,0]), max(plate_location[:,0][:,0])\n",
    "cropped_image = img[x1:x2, y1:y2]\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "all_reads = reader.readtext(cropped_image)\n",
    "license_plate = \"\".join(map(lambda read: read[-2], all_reads))\n",
    "print(license_plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6abe999-80a9-4cfd-8449-9ec77ff2036e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "license_plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54b590f-ad12-4116-a849-1d09f0fc423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/Users/rozidatululummiah/Downloads/Tensorflow/models/research/object_detection.h5')\n",
    "print('Model loaded Sucessfully')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
